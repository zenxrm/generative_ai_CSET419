{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJNZ_5Y_b8lR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXcLh0IVdqI9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2xsYYAwd6GI"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "LATENT_DIM = 128\n",
        "IMG_SIZE = 64\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "N_CRITIC = 3\n",
        "LAMBDA_GP = 10\n",
        "LR = 0.0002\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Lab_2_GAN/WGAN_GP\"\n",
        "IMG_DIR = os.path.join(BASE_DIR, \"images\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "CKPT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
        "\n",
        "os.makedirs(IMG_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhILt1sUd8Fi"
      },
      "outputs": [],
      "source": [
        "\n",
        " (x_train, y_train), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 127.5 - 1.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_train = tf.image.resize(x_train, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(60000).batch(BATCH_SIZE, drop_remainder=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwfPN06leGHq"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    noise = layers.Input(shape=(LATENT_DIM,))\n",
        "    label = layers.Input(shape=(NUM_CLASSES,))\n",
        "\n",
        "    x = layers.Concatenate()([noise, label])\n",
        "\n",
        "    x = layers.Dense(8 * 8 * 512, use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Reshape((8, 8, 512))(x)\n",
        "\n",
        "    # 8x8 -> 16x16\n",
        "    x = layers.Conv2DTranspose(256, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # 16x16 -> 32x32\n",
        "    x = layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # 32x32 -> 64x64\n",
        "    x = layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Final output (NO upsample here)\n",
        "    img = layers.Conv2D(\n",
        "        1, kernel_size=3, padding=\"same\", activation=\"tanh\"\n",
        "    )(x)\n",
        "\n",
        "    return tf.keras.Model([noise, label], img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XohrHkL6eJ0x"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    img = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
        "    label = layers.Input(shape=(NUM_CLASSES,))\n",
        "\n",
        "    label_map = layers.Dense(IMG_SIZE * IMG_SIZE)(label)\n",
        "    label_map = layers.Reshape((IMG_SIZE, IMG_SIZE, 1))(label_map)\n",
        "\n",
        "    x = layers.Concatenate()([img, label_map])\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding=\"same\")(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding=\"same\")(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding=\"same\")(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(512, 4, strides=2, padding=\"same\")(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "\n",
        "    return tf.keras.Model([img, label], out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSjBa6a4eLhf"
      },
      "outputs": [],
      "source": [
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "g_opt = tf.keras.optimizers.Adam(LR, beta_1=0.0, beta_2=0.9)\n",
        "d_opt = tf.keras.optimizers.Adam(LR, beta_1=0.0, beta_2=0.9)\n",
        "\n",
        "# Force build\n",
        "_ = generator([tf.random.normal((1, LATENT_DIM)), tf.one_hot([0], NUM_CLASSES)])\n",
        "_ = discriminator([tf.random.normal((1, IMG_SIZE, IMG_SIZE, 1)), tf.one_hot([0], NUM_CLASSES)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZOG3inVgaNe"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(real, fake, labels):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    interpolated = real * alpha + fake * (1 - alpha)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated)\n",
        "        pred = discriminator([interpolated, labels], training=True)\n",
        "\n",
        "    grads = tape.gradient(pred, interpolated)\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1,2,3]))\n",
        "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "    return gp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jTA_MgLeNET"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(real_imgs, labels):\n",
        "    for _ in range(N_CRITIC):\n",
        "        noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_imgs = generator([noise, labels], training=True)\n",
        "            real_out = discriminator([real_imgs, labels], training=True)\n",
        "            fake_out = discriminator([fake_imgs, labels], training=True)\n",
        "            gp = gradient_penalty(real_imgs, fake_imgs, labels)\n",
        "            d_loss = tf.reduce_mean(fake_out) - tf.reduce_mean(real_out) + LAMBDA_GP * gp\n",
        "\n",
        "        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "        d_opt.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
        "\n",
        "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "    with tf.GradientTape() as tape:\n",
        "        fake_imgs = generator([noise, labels], training=True)\n",
        "        fake_out = discriminator([fake_imgs, labels], training=True)\n",
        "        g_loss = -tf.reduce_mean(fake_out)\n",
        "\n",
        "    grads = tape.gradient(g_loss, generator.trainable_variables)\n",
        "    g_opt.apply_gradients(zip(grads, generator.trainable_variables))\n",
        "\n",
        "    return d_loss, g_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS1wwKm1eO0j"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_images(epoch):\n",
        "    noise = tf.random.normal([25, LATENT_DIM])\n",
        "    labels = tf.one_hot(np.random.randint(0,10,25), NUM_CLASSES)\n",
        "    imgs = generator([noise, labels], training=False)\n",
        "    imgs = (imgs + 1) / 2\n",
        "\n",
        "    fig, axs = plt.subplots(5,5, figsize=(6,6))\n",
        "    idx = 0\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            axs[i,j].imshow(imgs[idx,:,:,0], cmap=\"gray\")\n",
        "            axs[i,j].axis(\"off\")\n",
        "            idx+=1\n",
        "    plt.savefig(os.path.join(IMG_DIR, f\"epoch_{epoch}.png\"))\n",
        "    display(fig)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h66iXhYHBrMI"
      },
      "outputs": [],
      "source": [
        "epoch_var = tf.Variable(0, dtype=tf.int64)\n",
        "\n",
        "ckpt = tf.train.Checkpoint(\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    g_opt=g_opt,\n",
        "    d_opt=d_opt,\n",
        "    epoch=epoch_var\n",
        ")\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, CKPT_DIR, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(f\"âœ… Resumed from checkpoint at epoch {int(epoch_var.numpy())}\")\n",
        "else:\n",
        "    print(\"ðŸš€ No checkpoint found. Starting from scratch.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrikY7qnqyhF"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_epoch = int(epoch_var.numpy()) + 1\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
        "\n",
        "    bar = tqdm(dataset, leave=False)\n",
        "    for real_imgs, labels in bar:\n",
        "        d_loss, g_loss = train_step(real_imgs, labels)\n",
        "        bar.set_postfix(D_loss=f\"{d_loss:.3f}\", G_loss=f\"{g_loss:.3f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch} | D_loss: {d_loss:.3f} | G_loss: {g_loss:.3f}\")\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        save_images(epoch)\n",
        "\n",
        "    epoch_var.assign(epoch)      #  save epoch number\n",
        "    ckpt_manager.save()\n",
        "    print(\"ðŸ’¾ Checkpoint saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGjPw8lveTi_"
      },
      "outputs": [],
      "source": [
        "generator.save(os.path.join(MODEL_DIR, \"generator_final.h5\"))\n",
        "discriminator.save(os.path.join(MODEL_DIR, \"discriminator_final.h5\"))\n",
        "print(\"âœ… Final models saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gD1OLqt8i4N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_zYxAgNexLT"
      },
      "outputs": [],
      "source": [
        "# Restore latest checkpoint for evaluation\n",
        "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "\n",
        "print(\"Loaded checkpoint at epoch:\", int(epoch_var.numpy()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_var.assign(55)   # put your real trained epoch here\n",
        "print(\"Epoch corrected to:\", int(epoch_var.numpy()))\n"
      ],
      "metadata": {
        "id": "TTL83Y2vhv_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load real images\n",
        "(x_train, _), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 127.5 - 1.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_train = tf.image.resize(x_train, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "real_imgs = (x_train[:16] + 1) / 2\n",
        "\n",
        "# Generate fake images\n",
        "noise = tf.random.normal((16, LATENT_DIM))\n",
        "labels = tf.one_hot(np.random.randint(0, 10, 16), NUM_CLASSES)\n",
        "fake_imgs = (generator([noise, labels], training=False) + 1) / 2\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# REAL\n",
        "for i in range(16):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(real_imgs[i,:,:,0], cmap=\"gray\")\n",
        "    plt.title(\"Real\", fontsize=8)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# FAKE\n",
        "for i in range(16):\n",
        "    plt.subplot(4,8,16+i+1)\n",
        "    plt.imshow(fake_imgs[i,:,:,0], cmap=\"gray\")\n",
        "    plt.title(\"Fake\", fontsize=8)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\n",
        "    f\"Real vs Fake Images (WGAN-GP, Epoch {int(epoch_var.numpy())})\",\n",
        "    fontsize=14\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CPy_J4XviAxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSXaG5W9jGGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}